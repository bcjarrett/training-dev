ollama:
  ollama:
    # Port Ollama is listening on
    port: 11434

    gpu:
      enabled: true
      type: 'nvidia'
      number: 1
      nvidiaResource: "nvidia.com/gpu"

    models:
      # -- List of models to pull at container startup
      # The more you add, the longer the container will take to start if models are not present
      # pull:
      #  - llama2
      #  - mistral
      pull: []

      # -- List of models to load in memory at container startup
      # run:
      #  - llama2
      #  - mistral
      run: []

      # -- List of models to create at container startup, there are two options
      # 1. Create a raw model
      # 2. Load a model from configMaps, configMaps must be created before and are loaded as volume in "/models" directory.
      # create:
      #  - name: llama3.1-ctx32768
      #    configMapRef: my-configmap
      #    configMapKeyRef: configmap-key
      #  - name: llama3.1-ctx32768
      #    template: |
      #      FROM llama3.1
      #      PARAMETER num_ctx 32768
      create: []

    insecure: false

  # -- Specify runtime class
  runtimeClassName: "nvidia"

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-RTX-A4000-SHARED
                  - NVIDIA-RTX-A4000

  ingress:
    enabled: true
    ingressClassName: "traefik"
    additionalLabels: {}
    annotations:
      cert-manager.io/cluster-issuer: lets-encrypt
    hosts:
      - host: ollama.local.jarrett.page
        paths:
          - path: /
            pathType: Prefix
            servicePort: 6333
    tls:
      - hosts:
          - ollama.local.jarrett.page
        secretName: ollama-tls

resources:
  limits:
    cpu: 8
    memory: 16Gi
    nvidia.com/gpu: 1
  requests:
    cpu: 2
    memory: 2Gi
    nvidia.com/gpu: 1
  persistentVolume:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 30Gi
    storageClass: "nfs-lilnasx"

  tests:
    enabled: true
    labels: {}
